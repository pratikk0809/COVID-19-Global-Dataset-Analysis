# COVID-19 Global Dataset Analysis

An end-to-end data analytics project that explores and visualizes the global COVID-19 dataset using **Apache Spark (PySpark)** for scalable processing and **Pandas/Seaborn/Matplotlib** for visual insights. The project is designed and executed in **Jupyter Notebook** via the **Anaconda** environment.

---

## 🚀 Features

- Clean and structured ETL process using **PySpark DataFrame API**
- Time-series visualization of confirmed cases for **India**
- Bar charts for:
  - **Top 10 countries** by confirmed cases
  - **Daily confirmed cases** in India
- Reusable modular code with separate files for visualization and analysis
- Designed for large-scale dataset handling using Spark

---

## 📊 Sample Visuals

- `india_daily_confirmed.png`: Line chart of confirmed cases in India
- `india_bar_confirmed.png`: Bar chart of daily confirmed cases in India
- `top_countries.png`: Top 10 countries by confirmed cases (horizontal bar chart)

All plots are saved in the `plots/` directory.

---

## 🧰 Tech Stack

| Category        | Tools Used                              |
|----------------|------------------------------------------|
| Language        | Python                                   |
| Framework       | PySpark (Spark SQL)                      |
| Visualization   | Pandas, Matplotlib, Seaborn              |
| Environment     | Jupyter Notebook (Anaconda)              |
| Dataset         | COVID-19 global time series CSV dataset  |
| File Management | Modular Python scripts (`.py` files)     |

---

## 📁 Folder Structure

📦 covid-analysis/
┣ 📂 plots/ # Output images of visualizations
┣ 📜 etl_pipeline.ipynb # Main Jupyter Notebook
┣ 📜 visualization.py # Python module for all plots
┣ 📜 README.md # Project documentation

---

## ✅ Skills Demonstrated

- **Data Processing** with PySpark (`groupBy`, `agg`, `filter`, etc.)
- **Data Wrangling** using Pandas
- **Visual Storytelling** using Seaborn and Matplotlib
- **Modular Coding** in Python
- **Large Dataset Handling** using Spark for performance
- **Version Control** using Git & GitHub

---

